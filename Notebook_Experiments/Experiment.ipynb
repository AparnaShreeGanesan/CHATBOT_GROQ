{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file or environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Make sure to set your actual Groq API key in .env file or environment\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"Warning: GROQ_API_KEY not set. Please add it to your .env file or set it as an environment variable.\")\n",
    "else:\n",
    "    os.environ[\"GROQ_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0.6, groq_api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain of Verification ===\n",
      "\n",
      "Step 1: Initial Response\n",
      "Response: The capital of India is New Delhi.\n",
      "\n",
      "Step 2: Verification Check\n",
      "Verification: Accuracy: Yes\n",
      "Bias: No\n",
      "Confidence: High\n",
      "\n",
      "The response accurately states that the capital of India is New Delhi, which is a verifiable fact. There is no apparent bias in the statement, as it simply presents a neutral, factual piece of information. The confidence level is high because the statement is direct and assertive, with no hesitation or ambiguity.\n",
      "\n",
      "Step 3: Confidence Assessment\n",
      "Confidence Level: High\n",
      "\n",
      "=== Final Result ===\n",
      "Answer: The capital of India is New Delhi.\n",
      "Confidence: High\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of India\"\n",
    "\n",
    "# Chain of Verification Approach\n",
    "print(\"=== Chain of Verification ===\\n\")\n",
    "\n",
    "# Step 1: Initial response\n",
    "print(\"Step 1: Initial Response\")\n",
    "initial_response = llm.invoke(text)\n",
    "initial_text = initial_response.content if hasattr(initial_response, 'content') else str(initial_response)\n",
    "print(f\"Response: {initial_text}\\n\")\n",
    "\n",
    "# Step 2: Verification\n",
    "print(\"Step 2: Verification Check\")\n",
    "verification_prompt = f\"\"\"Review this response for accuracy and bias:\n",
    "Response: {initial_text}\n",
    "\n",
    "Evaluate:\n",
    "1. Accuracy (Yes/No)\n",
    "2. Bias (Yes/No)\n",
    "3. Confidence (High/Medium/Low)\n",
    "\n",
    "Format: Accuracy: []/Bias: []/Confidence: []\"\"\"\n",
    "\n",
    "verification = llm.invoke(verification_prompt)\n",
    "verification_text = verification.content if hasattr(verification, 'content') else str(verification)\n",
    "print(f\"Verification: {verification_text}\\n\")\n",
    "\n",
    "# Step 3: Confidence extraction\n",
    "print(\"Step 3: Confidence Assessment\")\n",
    "if \"Confidence: High\" in verification_text:\n",
    "    confidence = \"High\"\n",
    "elif \"Confidence: Low\" in verification_text:\n",
    "    confidence = \"Low\"\n",
    "else:\n",
    "    confidence = \"Medium\"\n",
    "print(f\"Confidence Level: {confidence}\\n\")\n",
    "\n",
    "print(\"=== Final Result ===\")\n",
    "print(f\"Answer: {initial_text}\")\n",
    "print(f\"Confidence: {confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HuggingFace API token from environment\n",
    "hf_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "if not hf_token:\n",
    "    print(\"Warning: HUGGINGFACEHUB_API_TOKEN not set. Please add it to your .env file.\")\n",
    "else:\n",
    "    os.environ['HUGGINGFACEHUB_API_TOKEN'] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing HuggingFaceHub: ImportError: cannot import name 'HuggingFaceHub' from 'langchain_huggingface' (/Users/bhuvaneswari/Downloads/Chatbot-Using-Langchain-main/.venv/lib/python3.14/site-packages/langchain_huggingface/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain_huggingface import HuggingFaceHub\n",
    "    llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})\n",
    "    print(\"HuggingFaceHub initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing HuggingFaceHub: {type(e).__name__}: {e}\")\n",
    "    llm_huggingface = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceHub not available. Skipping this cell.\n"
     ]
    }
   ],
   "source": [
    "if llm_huggingface:\n",
    "    try:\n",
    "        output = llm_huggingface.invoke(\"Capital of Russia\")\n",
    "        output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "else:\n",
    "    print(\"HuggingFaceHub not available. Skipping this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceHub not available. Skipping this cell.\n"
     ]
    }
   ],
   "source": [
    "if llm_huggingface:\n",
    "    try:\n",
    "        output = llm_huggingface.invoke(\"Write a poem about ai\")\n",
    "        output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "else:\n",
    "    print(\"HuggingFaceHub not available. Skipping this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    llm.invoke(\"Write a poem about ai\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")\n",
    "    print(\"Please ensure your OpenAI API key is valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"country\"],template=\"What is the capital of {country}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of India'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: langchain.chains module not available in this version of LangChain\n",
      "Using prompt + llm directly instead:\n",
      "Error: BadRequestError: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain.chains import LLMChain\n",
    "    chain = LLMChain(llm=llm,prompt=prompt_template)\n",
    "    print(chain.invoke({\"country\":\"India\"})[\"text\"])\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Note: langchain.chains module not available in this version of LangChain\")\n",
    "    print(\"Using prompt + llm directly instead:\")\n",
    "    try:\n",
    "        from langchain_core.prompts import PromptTemplate\n",
    "        prompt = prompt_template.format(country=\"India\")\n",
    "        result = llm.invoke(prompt)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m capital_prompt = PromptTemplate(input_variables=[\u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      2\u001b[39m                                 template=\u001b[33m\"\u001b[39m\u001b[33mPlease tell me the capital of the \u001b[39m\u001b[38;5;132;01m{country}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m capital_chain = \u001b[43mLLMChain\u001b[49m(llm=llm,prompt=capital_prompt)\n\u001b[32m      6\u001b[39m famous_template = PromptTemplate(input_variables=[\u001b[33m\"\u001b[39m\u001b[33mcapital\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m                                  template=\u001b[33m\"\u001b[39m\u001b[33mWhat is the most famous thing about \u001b[39m\u001b[38;5;132;01m{capital}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_prompt)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=[\"capital\"],\n",
    "                                 template=\"What is the most famous thing about {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m famous_chain = \u001b[43mLLMChain\u001b[49m(llm=llm,prompt=famous_template)\n",
      "\u001b[31mNameError\u001b[39m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "famous_chain = LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleSequentialChain\n\u001b[32m      2\u001b[39m chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n\u001b[32m      4\u001b[39m chain.invoke({\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mIndia\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "\n",
    "chain.invoke({\"input\":\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m capital_prompt = PromptTemplate(input_variables=[\u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      2\u001b[39m                                 template=\u001b[33m\"\u001b[39m\u001b[33mPlease tell me the capital of the \u001b[39m\u001b[38;5;132;01m{country}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m capital_chain = \u001b[43mLLMChain\u001b[49m(llm=llm,prompt=capital_prompt,output_key=\u001b[33m\"\u001b[39m\u001b[33mcapital\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_prompt,output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m famous_template = PromptTemplate(input_variables=[\u001b[33m\"\u001b[39m\u001b[33mcapital\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      2\u001b[39m                                  template=\u001b[33m\"\u001b[39m\u001b[33mWhat is the most famous thing about \u001b[39m\u001b[38;5;132;01m{capital}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m famous_chain = \u001b[43mLLMChain\u001b[49m(llm=llm,prompt=famous_template,output_key=\u001b[33m\"\u001b[39m\u001b[33mPlaces\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "famous_template = PromptTemplate(input_variables=[\"capital\"],\n",
    "                                 template=\"What is the most famous thing about {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm,prompt=famous_template,output_key=\"Places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SequentialChain\n\u001b[32m      2\u001b[39m chain = SequentialChain(chains=[capital_chain,famous_chain],\n\u001b[32m      3\u001b[39m                         input_variables=[\u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m                         output_variables=[\u001b[33m\"\u001b[39m\u001b[33mcapital\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mPlaces\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chain],\n",
    "                        input_variables=[\"country\"],\n",
    "                        output_variables=[\"capital\",\"Places\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchain\u001b[49m({\u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mIndia\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[31mNameError\u001b[39m: name 'chain' is not defined"
     ]
    }
   ],
   "source": [
    "chain({\"country\":\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatModels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatOpenAI' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchatllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a comedian AI Assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTell me a joke\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'ChatOpenAI' object is not callable"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = chatllm.invoke([\n",
    "        SystemMessage(content=\"You are a comedian AI Assistant\"),\n",
    "        HumanMessage(content=\"Tell me a joke\")\n",
    "    ])\n",
    "    result\n",
    "except Exception as e:\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")\n",
    "    print(\"Please ensure your OpenAI API key is valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Ouput Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outputa(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. when uer gives any input you should generate 5 words synonynms which should be Outputa\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|Outputa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-ggZa8**********************************xbZJ. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}\n",
      "Please ensure your OpenAI API key is valid\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chain.invoke({\"text\":\"intelligent\"})\n",
    "except Exception as e:\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")\n",
    "    print(\"Please ensure your OpenAI API key is valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
